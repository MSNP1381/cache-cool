{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_cool_uri=\"http://127.0.0.1:8000/avalai\"\n",
    "cache_cool_base_uri=\"http://127.0.0.1:8000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "OPENAI_API_KEY=os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI_API_KEY=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# reqUrl = \"https://api.openai.com/v1/chat/completions\"\n",
    "reqUrl = f\"{cache_cool_uri}/chat/completions\"\n",
    "\n",
    "headersList = {\n",
    " \"Accept\": \"*/*\",\n",
    " \"User-Agent\": \"Thunder Client (https://www.thunderclient.com)\",\n",
    " \"Content-Type\": \"application/json\",\n",
    " \"Authorization\": f\"Bearer {OPENAI_API_KEY}\" \n",
    "}\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hello, how can I use ChatGPT with Claude?\"\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 100\n",
    "})\n",
    "\n",
    "response = requests.request(\"POST\", reqUrl, data=payload,  headers=headersList)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# from langchain.prompts.chat import , HumanMessage\n",
    "\n",
    "# Initialize the chat model\n",
    "chat = ChatOpenAI(base_url=cache_cool_uri, openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Create messages\n",
    "messages = [\n",
    "    (\"system\",\"You are a helpful assistant.\"),\n",
    "    (\"user\",\"Can you explain how to use Claude?\")\n",
    "]\n",
    "\n",
    "# Get a response\n",
    "response = chat(messages)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "# Set your OpenAI API key\n",
    "# openai.api_key =OPENAI_API_KEY\n",
    "\n",
    "cli=openai.OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=cache_cool_uri\n",
    ")\n",
    "# Define the prompt\n",
    "prompt = \"Hello, how can I use ChatGPT with Claude?\"\n",
    "\n",
    "\n",
    "\n",
    "# Generate a response\n",
    "response =cli.chat.completions.create(\n",
    "    \n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[prompt],\n",
    "    max_tokens=100,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "# Print the generated response\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response=requests.get(cache_cool_base_uri+'configure')\n",
    "configure_response=response.json()\n",
    "configure_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL for the configure endpoint\n",
    "url = \"http://localhost:8000/configure\"  # Replace with the actual URL of your FastAPI server\n",
    "\n",
    "# Complete payload with all required fields\n",
    "payload = {\n",
    "    \"llm_schemas\": {\n",
    "        \"gemini\": {\n",
    "            \"endpoint\": \"https://api.google.com/v1/chat/completions\",\n",
    "            \"headers\": [\n",
    "                \"Content-Type: application/json\",\n",
    "                \"Authorization: Bearer {api_key}\"\n",
    "            ],\n",
    "            \"temperature_threshold\": 0.8\n",
    "        }\n",
    "    },\n",
    "    \"mongodb\": {\n",
    "        \"uri\": \"mongodb://localhost:27017\",\n",
    "        \"db_name\": \"test_db\",\n",
    "        \"collection_name\": \"test_collection\"\n",
    "    },\n",
    "    \"json_cache_file\": \"cache.json\",\n",
    "    \"redis\": {\n",
    "        \"enabled\": False,\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 6379,\n",
    "        \"db\": 0\n",
    "    },\n",
    "    \"current_llm_service\": \"gemini\",\n",
    "    \"use_json_cache\": True,\n",
    "    \"use_mongo_cache\": True\n",
    "}\n",
    "\n",
    "payload['llm_schemas'].update(configure_response[\"llm_schemas\"])\n",
    "# Send the PUT request with the complete payload as JSON\n",
    "response = requests.put(url, json=payload)\n",
    "\n",
    "# Print the response from the server\n",
    "if response.status_code == 200:\n",
    "    print(\"Configuration updated successfully:\", response.json())\n",
    "else:\n",
    "    print(f\"Failed to update configuration. Status code: {response.status_code}\")\n",
    "    print(\"Response:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
